{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: Data Science"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir('C:\\\\Users\\\\akash\\\\Desktop\\\\AppScrip\\\\New folder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('sample_train.csv', header = 0)\n",
    "test = pd.read_csv('sample_test.csv', header = 0)\n",
    "train = train.drop('Unnamed: 0', axis =1)\n",
    "test = test.drop('Unnamed: 0', axis =1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape (169, 8)\n",
      "test Shape (50, 8)\n"
     ]
    }
   ],
   "source": [
    "print('Train Shape',train.shape)\n",
    "print(\"test Shape\",test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All the features are binary categorical data set\n",
    "so the possible combination are 2^8 = 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the dummy numpy array similar to the dimension of the dataset\n",
    "dummy_train = pd.DataFrame(np.random.randint(2, size = (250,8)), columns = train.columns.values)\n",
    "dummy_test = pd.DataFrame(np.random.randint(2, size = (50,8)), columns= train.columns.values)\n",
    "#Concatination the dataset by dropping the dumplicate values\n",
    "train = pd.concat([train,dummy_train]).drop_duplicates().reset_index(drop = True)\n",
    "test = pd.concat([test,dummy_test]).drop_duplicates().reset_index(drop = True)\n",
    "# Creating the balance target value with balance data set\n",
    "target_val = np.array(train[train.columns.values[4]])\n",
    "np.random.shuffle(target_val)\n",
    "train['target'] = target_val\n",
    "target_test = np.array(test[test.columns.values[-2]])\n",
    "np.random.shuffle(target_test)\n",
    "test['target'] = target_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = train.drop('target', axis =1)\n",
    "y_train = train['target']\n",
    "x_test = test.drop('target', axis = 1)\n",
    "y_test = test['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtree_gini = tree.DecisionTreeClassifier(random_state= 42).fit(x_train,y_train)# Default Gini Index\n",
    "dtree_entropy = tree.DecisionTreeClassifier(criterion='entropy', random_state= 42).fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "gini_predict = dtree_gini.predict(x_test)\n",
    "entropy_predict = dtree_entropy.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('gini_tree.txt', 'w') as f:\n",
    "    f = tree.export_graphviz(dtree_gini, out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('entropy_tree.txt', 'w') as f:\n",
    "    f = tree.export_graphviz(dtree_entropy, out_file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_metrics(y_true,y_predict):\n",
    "    confuse = confusion_matrix(y_true, y_predict)\n",
    "    print(confuse)\n",
    "    tn, fp, fn, tp = confuse.ravel()\n",
    "    print('Accurary =', (tn+tp)/(tn+fp+fn+tp))\n",
    "    print('Error = ', 1- ((tn+tp)/(tn+fp+fn+tp)))\n",
    "    print(\"TPR =\",tp/(fp+tp))\n",
    "    print(\"TNR =\",tn/(tn+fp))\n",
    "    print(\"FPR =\",fp/(tn+fp))\n",
    "    print(\"FNR =\",fn/(fp+tp))\n",
    "    print('Precision =', tp/(tp+fp))\n",
    "    print('Recall =', tp/(tp+fn))\n",
    "    from sklearn.metrics import f1_score\n",
    "    print('F1_score :', f1_score(y_true,y_predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 15]\n",
      " [ 9 15]]\n",
      "Accurary = 0.52\n",
      "Error =  0.48\n",
      "TPR = 0.5\n",
      "TNR = 0.4230769230769231\n",
      "FPR = 0.5769230769230769\n",
      "FNR = 0.3\n",
      "Precision = 0.5\n",
      "Recall = 0.625\n",
      "F1_score : 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "#GINI CONFUSION METRIX\n",
    "confusion_matrix(y_test, gini_predict)\n",
    "error_metrics(y_test, gini_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[11 15]\n",
      " [ 9 15]]\n",
      "Accurary = 0.52\n",
      "Error =  0.48\n",
      "TPR = 0.5\n",
      "TNR = 0.4230769230769231\n",
      "FPR = 0.5769230769230769\n",
      "FNR = 0.3\n",
      "Precision = 0.5\n",
      "Recall = 0.625\n",
      "F1_score : 0.5555555555555556\n"
     ]
    }
   ],
   "source": [
    "#Entropy CONFUSION METRIX\n",
    "confusion_matrix(y_test, entropy_predict)\n",
    "error_metrics(y_test, entropy_predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance of both the algorithms are same but the accuracy of an algorithm is 52% where as the precision of an algorithm is 50% and recall rate in 62.5%.\n",
    "F1-score(Harmonic mean of precision and recall) = 55.555\n",
    "\n",
    "Detailed explanation of the algorithm is on DecisionTree.docx file"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
